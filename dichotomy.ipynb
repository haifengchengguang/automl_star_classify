{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4172\\1433843627.py:9: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(data_path) # path to colab notebook #replace this with the path to your dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": "   W1mag-W2mag  W2mag-W3mag  Jmag-Hmag  Jmag-W1mag  Jmag-W2mag  Jmag-Kmag  \\\n0     0.290000        0.824   0.846000    2.123000    2.413000   1.515000   \n1     0.297999        1.277   0.860999    1.724000    2.021999   1.433000   \n2     0.326000        1.328   1.146000    2.237000    2.563000   1.566000   \n3     0.492001        1.438   0.837000    2.266999    2.759000   1.407000   \n4     0.316000        0.303   0.908000    2.028999    2.344999   1.481999   \n\n   subclass  \n0         0  \n1         0  \n2         0  \n3         0  \n4         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>W1mag-W2mag</th>\n      <th>W2mag-W3mag</th>\n      <th>Jmag-Hmag</th>\n      <th>Jmag-W1mag</th>\n      <th>Jmag-W2mag</th>\n      <th>Jmag-Kmag</th>\n      <th>subclass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.290000</td>\n      <td>0.824</td>\n      <td>0.846000</td>\n      <td>2.123000</td>\n      <td>2.413000</td>\n      <td>1.515000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.297999</td>\n      <td>1.277</td>\n      <td>0.860999</td>\n      <td>1.724000</td>\n      <td>2.021999</td>\n      <td>1.433000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.326000</td>\n      <td>1.328</td>\n      <td>1.146000</td>\n      <td>2.237000</td>\n      <td>2.563000</td>\n      <td>1.566000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.492001</td>\n      <td>1.438</td>\n      <td>0.837000</td>\n      <td>2.266999</td>\n      <td>2.759000</td>\n      <td>1.407000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.316000</td>\n      <td>0.303</td>\n      <td>0.908000</td>\n      <td>2.028999</td>\n      <td>2.344999</td>\n      <td>1.481999</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path= \"result_20220309_color.csv\"\n",
    "df=pd.read_csv(data_path) # path to colab notebook #replace this with the path to your dataset\n",
    "df_use=df.iloc[:,4:11]\n",
    "df_use.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./dich_BD/\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (627047 samples, 57.04 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./dich_BD/\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.11\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    627047\n",
      "Train Data Columns: 6\n",
      "Label Column: subclass\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3345.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 30.1 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['W1mag-W2mag', 'W2mag-W3mag', 'Jmag-Hmag', 'Jmag-W1mag', 'Jmag-W2mag', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['W1mag-W2mag', 'W2mag-W3mag', 'Jmag-Hmag', 'Jmag-W1mag', 'Jmag-W2mag', ...]\n",
      "\t0.9s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 30.1 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 620776, Val Rows: 6271\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9925\t = Validation score   (accuracy)\n",
      "\t2.91s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9925\t = Validation score   (accuracy)\n",
      "\t2.75s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t101.51s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t95.2s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 262 due to low memory. Expected memory usage reduced from 17.13% -> 15.0% of available memory...\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t36.53s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 278 due to low memory. Expected memory usage reduced from 16.17% -> 15.0% of available memory...\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t39.73s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t236.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "D:\\conda\\envs\\automl\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t277.34s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.9931\t = Validation score   (accuracy)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9931\t = Validation score   (accuracy)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 810.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./dich_BD/\\\")\n"
     ]
    }
   ],
   "source": [
    "#bd_data = TabularDataset(data_path)\n",
    "df_train,df_test=train_test_split(df_use,test_size=0.15,random_state=1)\n",
    "#test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "save_path = './dich_BD/'\n",
    "predictor = TabularPredictor(label='subclass',path=save_path).fit(train_data=df_train,ag_args_fit={'num_gpus': 1})\n",
    "#num_stack_levels=1,num_bag_folds=5\n",
    "#predictions = predictor.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}